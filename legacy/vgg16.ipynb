{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\t\t\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "vgg_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "x = vgg_model.output\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(136, activation='relu')(x) # Softmax for multiclass\n",
    "transfer_model = tf.keras.Model(inputs=vgg_model.input, outputs=x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('vgg16_finetune.h15', monitor= 'val_accuracy', mode='max', save_best_only=True, verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "learning_rate= 5e-5\n",
    "transfer_model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\n",
    "from libs.dp import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# checkpoint\n",
    "\n",
    "checkpoint_path = \"data/checkpoint_vgg16/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')\n",
    "\n",
    "transfer_model.save_weights(checkpoint_path.format(epoch=0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "IMG_RES = 256\n",
    "HMS_RES = 64\n",
    "NUM_LANDMARKS = 68\n",
    "BATCH_SIZE = 16\n",
    "DATASET_DIR = '../Data/300W_train/train.csv'\n",
    "\n",
    "dataset = Dataset(IMG_RES, HMS_RES, NUM_LANDMARKS, DATASET_DIR)\n",
    "# dataset_generator = "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset: ../Data/300W_train/train.csv\n",
      "Train dataset is loaded. Shape: (3837, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tf_dataset = tf.data.Dataset.from_generator(dataset.gen_vgg16,\n",
    "                                            output_types=(np.float32, np.float32),\n",
    "                                            output_shapes=(\n",
    "                                                [IMG_RES, IMG_RES, 3],\n",
    "                                                [NUM_LANDMARKS * 2]),\n",
    "                                            args=()).repeat().batch(BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "VAL_DIR = '../Data/300W/eval.csv'\n",
    "val_dataset = Dataset(IMG_RES, HMS_RES, NUM_LANDMARKS, VAL_DIR)\n",
    "val_tf_dataset = tf.data.Dataset.from_generator(dataset.gen_vgg16,\n",
    "                                                output_types=(np.float32, np.float32),\n",
    "                                                output_shapes=(\n",
    "                                                    [IMG_RES, IMG_RES, 3],\n",
    "                                                    [NUM_LANDMARKS * 2]),\n",
    "                                                args=()).repeat().batch(BATCH_SIZE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset: ../Data/300W/eval.csv\n",
      "Train dataset is loaded. Shape: (600, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "hist = transfer_model.fit(tf_dataset.take(240), validation_data=val_tf_dataset.take(19), callbacks=[lr_reduce, cp_callback], epochs=120)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/120\n",
      "240/240 [==============================] - 283s 1s/step - loss: 0.0652 - accuracy: 0.0557 - val_loss: 0.0184 - val_accuracy: 0.0329\n",
      "\n",
      "Epoch 00001: saving model to data/checkpoint_vgg16/cp-0001.ckpt\n",
      "Epoch 2/120\n",
      "240/240 [==============================] - 279s 1s/step - loss: 0.0268 - accuracy: 0.1010 - val_loss: 0.0162 - val_accuracy: 0.1118\n",
      "\n",
      "Epoch 00002: saving model to data/checkpoint_vgg16/cp-0002.ckpt\n",
      "Epoch 3/120\n",
      "240/240 [==============================] - 278s 1s/step - loss: 0.0186 - accuracy: 0.1198 - val_loss: 0.0134 - val_accuracy: 0.2007\n",
      "\n",
      "Epoch 00003: saving model to data/checkpoint_vgg16/cp-0003.ckpt\n",
      "Epoch 4/120\n",
      "240/240 [==============================] - 279s 1s/step - loss: 0.0156 - accuracy: 0.1154 - val_loss: 0.0098 - val_accuracy: 0.1941\n",
      "\n",
      "Epoch 00004: saving model to data/checkpoint_vgg16/cp-0004.ckpt\n",
      "Epoch 5/120\n",
      "240/240 [==============================] - 279s 1s/step - loss: 0.0144 - accuracy: 0.1464 - val_loss: 0.0097 - val_accuracy: 0.2664\n",
      "\n",
      "Epoch 00005: saving model to data/checkpoint_vgg16/cp-0005.ckpt\n",
      "Epoch 6/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0136 - accuracy: 0.1286 - val_loss: 0.0096 - val_accuracy: 0.2467\n",
      "\n",
      "Epoch 00006: saving model to data/checkpoint_vgg16/cp-0006.ckpt\n",
      "Epoch 7/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0131 - accuracy: 0.1284 - val_loss: 0.0097 - val_accuracy: 0.2237\n",
      "\n",
      "Epoch 00007: saving model to data/checkpoint_vgg16/cp-0007.ckpt\n",
      "Epoch 8/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0125 - accuracy: 0.1401 - val_loss: 0.0094 - val_accuracy: 0.1316\n",
      "\n",
      "Epoch 00008: saving model to data/checkpoint_vgg16/cp-0008.ckpt\n",
      "Epoch 9/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0122 - accuracy: 0.1505 - val_loss: 0.0096 - val_accuracy: 0.1053\n",
      "\n",
      "Epoch 00009: saving model to data/checkpoint_vgg16/cp-0009.ckpt\n",
      "Epoch 10/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0118 - accuracy: 0.1516 - val_loss: 0.0093 - val_accuracy: 0.0987\n",
      "\n",
      "Epoch 00010: saving model to data/checkpoint_vgg16/cp-0010.ckpt\n",
      "Epoch 11/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0115 - accuracy: 0.1487 - val_loss: 0.0090 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00011: saving model to data/checkpoint_vgg16/cp-0011.ckpt\n",
      "Epoch 12/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0113 - accuracy: 0.1536 - val_loss: 0.0086 - val_accuracy: 0.2763\n",
      "\n",
      "Epoch 00012: saving model to data/checkpoint_vgg16/cp-0012.ckpt\n",
      "Epoch 13/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0102 - accuracy: 0.1656 - val_loss: 0.0066 - val_accuracy: 0.1151\n",
      "\n",
      "Epoch 00013: saving model to data/checkpoint_vgg16/cp-0013.ckpt\n",
      "Epoch 14/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0087 - accuracy: 0.1628 - val_loss: 0.0070 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00014: saving model to data/checkpoint_vgg16/cp-0014.ckpt\n",
      "Epoch 15/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0085 - accuracy: 0.1609 - val_loss: 0.0066 - val_accuracy: 0.2599\n",
      "\n",
      "Epoch 00015: saving model to data/checkpoint_vgg16/cp-0015.ckpt\n",
      "Epoch 16/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0082 - accuracy: 0.1786 - val_loss: 0.0062 - val_accuracy: 0.3158\n",
      "\n",
      "Epoch 00016: saving model to data/checkpoint_vgg16/cp-0016.ckpt\n",
      "Epoch 17/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0081 - accuracy: 0.1880 - val_loss: 0.0066 - val_accuracy: 0.3026\n",
      "\n",
      "Epoch 00017: saving model to data/checkpoint_vgg16/cp-0017.ckpt\n",
      "Epoch 18/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0079 - accuracy: 0.1776 - val_loss: 0.0066 - val_accuracy: 0.2895\n",
      "\n",
      "Epoch 00018: saving model to data/checkpoint_vgg16/cp-0018.ckpt\n",
      "Epoch 19/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0078 - accuracy: 0.1956 - val_loss: 0.0063 - val_accuracy: 0.4243\n",
      "\n",
      "Epoch 00019: saving model to data/checkpoint_vgg16/cp-0019.ckpt\n",
      "Epoch 20/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0076 - accuracy: 0.2083 - val_loss: 0.0068 - val_accuracy: 0.2664\n",
      "\n",
      "Epoch 00020: saving model to data/checkpoint_vgg16/cp-0020.ckpt\n",
      "Epoch 21/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0075 - accuracy: 0.2031 - val_loss: 0.0062 - val_accuracy: 0.3849\n",
      "\n",
      "Epoch 00021: saving model to data/checkpoint_vgg16/cp-0021.ckpt\n",
      "Epoch 22/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0074 - accuracy: 0.2128 - val_loss: 0.0063 - val_accuracy: 0.3059\n",
      "\n",
      "Epoch 00022: saving model to data/checkpoint_vgg16/cp-0022.ckpt\n",
      "Epoch 23/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0072 - accuracy: 0.2188 - val_loss: 0.0063 - val_accuracy: 0.2993\n",
      "\n",
      "Epoch 00023: saving model to data/checkpoint_vgg16/cp-0023.ckpt\n",
      "Epoch 24/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0071 - accuracy: 0.2354 - val_loss: 0.0066 - val_accuracy: 0.3092\n",
      "\n",
      "Epoch 00024: saving model to data/checkpoint_vgg16/cp-0024.ckpt\n",
      "Epoch 25/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0071 - accuracy: 0.2383 - val_loss: 0.0061 - val_accuracy: 0.3487\n",
      "\n",
      "Epoch 00025: saving model to data/checkpoint_vgg16/cp-0025.ckpt\n",
      "Epoch 26/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0068 - accuracy: 0.2406 - val_loss: 0.0061 - val_accuracy: 0.3059\n",
      "\n",
      "Epoch 00026: saving model to data/checkpoint_vgg16/cp-0026.ckpt\n",
      "Epoch 27/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0068 - accuracy: 0.2419 - val_loss: 0.0062 - val_accuracy: 0.3289\n",
      "\n",
      "Epoch 00027: saving model to data/checkpoint_vgg16/cp-0027.ckpt\n",
      "Epoch 28/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0066 - accuracy: 0.2445 - val_loss: 0.0060 - val_accuracy: 0.3849\n",
      "\n",
      "Epoch 00028: saving model to data/checkpoint_vgg16/cp-0028.ckpt\n",
      "Epoch 29/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0065 - accuracy: 0.2549 - val_loss: 0.0058 - val_accuracy: 0.3520\n",
      "\n",
      "Epoch 00029: saving model to data/checkpoint_vgg16/cp-0029.ckpt\n",
      "Epoch 30/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0064 - accuracy: 0.2625 - val_loss: 0.0059 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00030: saving model to data/checkpoint_vgg16/cp-0030.ckpt\n",
      "Epoch 31/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0064 - accuracy: 0.2740 - val_loss: 0.0058 - val_accuracy: 0.3553\n",
      "\n",
      "Epoch 00031: saving model to data/checkpoint_vgg16/cp-0031.ckpt\n",
      "Epoch 32/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0063 - accuracy: 0.2721 - val_loss: 0.0058 - val_accuracy: 0.3257\n",
      "\n",
      "Epoch 00032: saving model to data/checkpoint_vgg16/cp-0032.ckpt\n",
      "Epoch 33/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0062 - accuracy: 0.2844 - val_loss: 0.0058 - val_accuracy: 0.3618\n",
      "\n",
      "Epoch 00033: saving model to data/checkpoint_vgg16/cp-0033.ckpt\n",
      "Epoch 34/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0061 - accuracy: 0.3026 - val_loss: 0.0058 - val_accuracy: 0.3783\n",
      "\n",
      "Epoch 00034: saving model to data/checkpoint_vgg16/cp-0034.ckpt\n",
      "Epoch 35/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0060 - accuracy: 0.2979 - val_loss: 0.0058 - val_accuracy: 0.3914\n",
      "\n",
      "Epoch 00035: saving model to data/checkpoint_vgg16/cp-0035.ckpt\n",
      "Epoch 36/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0060 - accuracy: 0.3081 - val_loss: 0.0057 - val_accuracy: 0.3322\n",
      "\n",
      "Epoch 00036: saving model to data/checkpoint_vgg16/cp-0036.ckpt\n",
      "Epoch 37/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0059 - accuracy: 0.3125 - val_loss: 0.0058 - val_accuracy: 0.3684\n",
      "\n",
      "Epoch 00037: saving model to data/checkpoint_vgg16/cp-0037.ckpt\n",
      "Epoch 38/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0059 - accuracy: 0.3250 - val_loss: 0.0057 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00038: saving model to data/checkpoint_vgg16/cp-0038.ckpt\n",
      "Epoch 39/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0059 - accuracy: 0.3216 - val_loss: 0.0056 - val_accuracy: 0.3783\n",
      "\n",
      "Epoch 00039: saving model to data/checkpoint_vgg16/cp-0039.ckpt\n",
      "Epoch 40/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0058 - accuracy: 0.3346 - val_loss: 0.0056 - val_accuracy: 0.3717\n",
      "\n",
      "Epoch 00040: saving model to data/checkpoint_vgg16/cp-0040.ckpt\n",
      "Epoch 41/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0058 - accuracy: 0.3440 - val_loss: 0.0057 - val_accuracy: 0.3520\n",
      "\n",
      "Epoch 00041: saving model to data/checkpoint_vgg16/cp-0041.ckpt\n",
      "Epoch 42/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0058 - accuracy: 0.3388 - val_loss: 0.0056 - val_accuracy: 0.4112\n",
      "\n",
      "Epoch 00042: saving model to data/checkpoint_vgg16/cp-0042.ckpt\n",
      "Epoch 43/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0058 - accuracy: 0.3404 - val_loss: 0.0056 - val_accuracy: 0.4013\n",
      "\n",
      "Epoch 00043: saving model to data/checkpoint_vgg16/cp-0043.ckpt\n",
      "Epoch 44/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0057 - accuracy: 0.3427 - val_loss: 0.0056 - val_accuracy: 0.3914\n",
      "\n",
      "Epoch 00044: saving model to data/checkpoint_vgg16/cp-0044.ckpt\n",
      "Epoch 45/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0057 - accuracy: 0.3518 - val_loss: 0.0056 - val_accuracy: 0.3586\n",
      "\n",
      "Epoch 00045: saving model to data/checkpoint_vgg16/cp-0045.ckpt\n",
      "Epoch 46/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0057 - accuracy: 0.3523 - val_loss: 0.0056 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00046: saving model to data/checkpoint_vgg16/cp-0046.ckpt\n",
      "Epoch 47/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0057 - accuracy: 0.3560 - val_loss: 0.0055 - val_accuracy: 0.4375\n",
      "\n",
      "Epoch 00047: saving model to data/checkpoint_vgg16/cp-0047.ckpt\n",
      "Epoch 48/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0057 - accuracy: 0.3638 - val_loss: 0.0055 - val_accuracy: 0.4243\n",
      "\n",
      "Epoch 00048: saving model to data/checkpoint_vgg16/cp-0048.ckpt\n",
      "Epoch 49/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0057 - accuracy: 0.3638 - val_loss: 0.0056 - val_accuracy: 0.4441\n",
      "\n",
      "Epoch 00049: saving model to data/checkpoint_vgg16/cp-0049.ckpt\n",
      "Epoch 50/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0057 - accuracy: 0.3792 - val_loss: 0.0056 - val_accuracy: 0.4013\n",
      "\n",
      "Epoch 00050: saving model to data/checkpoint_vgg16/cp-0050.ckpt\n",
      "Epoch 51/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0057 - accuracy: 0.3716 - val_loss: 0.0055 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 00051: saving model to data/checkpoint_vgg16/cp-0051.ckpt\n",
      "Epoch 52/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0056 - accuracy: 0.3745 - val_loss: 0.0055 - val_accuracy: 0.4441\n",
      "\n",
      "Epoch 00052: saving model to data/checkpoint_vgg16/cp-0052.ckpt\n",
      "Epoch 53/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0056 - accuracy: 0.3779 - val_loss: 0.0055 - val_accuracy: 0.4309\n",
      "\n",
      "Epoch 00053: saving model to data/checkpoint_vgg16/cp-0053.ckpt\n",
      "Epoch 54/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0056 - accuracy: 0.4023 - val_loss: 0.0054 - val_accuracy: 0.4770\n",
      "\n",
      "Epoch 00054: saving model to data/checkpoint_vgg16/cp-0054.ckpt\n",
      "Epoch 55/120\n",
      "240/240 [==============================] - 271s 1s/step - loss: 0.0056 - accuracy: 0.4026 - val_loss: 0.0054 - val_accuracy: 0.4638\n",
      "\n",
      "Epoch 00055: saving model to data/checkpoint_vgg16/cp-0055.ckpt\n",
      "Epoch 56/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0056 - accuracy: 0.4055 - val_loss: 0.0055 - val_accuracy: 0.3947\n",
      "\n",
      "Epoch 00056: saving model to data/checkpoint_vgg16/cp-0056.ckpt\n",
      "Epoch 57/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0056 - accuracy: 0.4039 - val_loss: 0.0055 - val_accuracy: 0.4572\n",
      "\n",
      "Epoch 00057: saving model to data/checkpoint_vgg16/cp-0057.ckpt\n",
      "Epoch 58/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0056 - accuracy: 0.4229 - val_loss: 0.0055 - val_accuracy: 0.5099\n",
      "\n",
      "Epoch 00058: saving model to data/checkpoint_vgg16/cp-0058.ckpt\n",
      "Epoch 59/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0056 - accuracy: 0.4049 - val_loss: 0.0055 - val_accuracy: 0.4868\n",
      "\n",
      "Epoch 00059: saving model to data/checkpoint_vgg16/cp-0059.ckpt\n",
      "Epoch 60/120\n",
      "240/240 [==============================] - 271s 1s/step - loss: 0.0056 - accuracy: 0.4193 - val_loss: 0.0055 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 00060: saving model to data/checkpoint_vgg16/cp-0060.ckpt\n",
      "Epoch 61/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0056 - accuracy: 0.4201 - val_loss: 0.0054 - val_accuracy: 0.4507\n",
      "\n",
      "Epoch 00061: saving model to data/checkpoint_vgg16/cp-0061.ckpt\n",
      "Epoch 62/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0056 - accuracy: 0.4167 - val_loss: 0.0055 - val_accuracy: 0.4276\n",
      "\n",
      "Epoch 00062: saving model to data/checkpoint_vgg16/cp-0062.ckpt\n",
      "Epoch 63/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0056 - accuracy: 0.4187 - val_loss: 0.0054 - val_accuracy: 0.4770\n",
      "\n",
      "Epoch 00063: saving model to data/checkpoint_vgg16/cp-0063.ckpt\n",
      "Epoch 64/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0056 - accuracy: 0.4198 - val_loss: 0.0055 - val_accuracy: 0.4638\n",
      "\n",
      "Epoch 00064: saving model to data/checkpoint_vgg16/cp-0064.ckpt\n",
      "Epoch 65/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0056 - accuracy: 0.4424 - val_loss: 0.0055 - val_accuracy: 0.5197\n",
      "\n",
      "Epoch 00065: saving model to data/checkpoint_vgg16/cp-0065.ckpt\n",
      "Epoch 66/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0056 - accuracy: 0.4336 - val_loss: 0.0055 - val_accuracy: 0.4868\n",
      "\n",
      "Epoch 00066: saving model to data/checkpoint_vgg16/cp-0066.ckpt\n",
      "Epoch 67/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0055 - accuracy: 0.4529 - val_loss: 0.0054 - val_accuracy: 0.5263\n",
      "\n",
      "Epoch 00067: saving model to data/checkpoint_vgg16/cp-0067.ckpt\n",
      "Epoch 68/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0056 - accuracy: 0.4615 - val_loss: 0.0054 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 00068: saving model to data/checkpoint_vgg16/cp-0068.ckpt\n",
      "Epoch 69/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0055 - accuracy: 0.4542 - val_loss: 0.0054 - val_accuracy: 0.4836\n",
      "\n",
      "Epoch 00069: saving model to data/checkpoint_vgg16/cp-0069.ckpt\n",
      "Epoch 70/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0055 - accuracy: 0.4518 - val_loss: 0.0054 - val_accuracy: 0.5099\n",
      "\n",
      "Epoch 00070: saving model to data/checkpoint_vgg16/cp-0070.ckpt\n",
      "Epoch 71/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0055 - accuracy: 0.4451 - val_loss: 0.0054 - val_accuracy: 0.5066\n",
      "\n",
      "Epoch 00071: saving model to data/checkpoint_vgg16/cp-0071.ckpt\n",
      "Epoch 72/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0055 - accuracy: 0.4492 - val_loss: 0.0054 - val_accuracy: 0.5099\n",
      "\n",
      "Epoch 00072: saving model to data/checkpoint_vgg16/cp-0072.ckpt\n",
      "Epoch 73/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0055 - accuracy: 0.4549 - val_loss: 0.0054 - val_accuracy: 0.4671\n",
      "\n",
      "Epoch 00073: saving model to data/checkpoint_vgg16/cp-0073.ckpt\n",
      "Epoch 74/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0055 - accuracy: 0.4633 - val_loss: 0.0054 - val_accuracy: 0.4934\n",
      "\n",
      "Epoch 00074: saving model to data/checkpoint_vgg16/cp-0074.ckpt\n",
      "Epoch 75/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0055 - accuracy: 0.4516 - val_loss: 0.0054 - val_accuracy: 0.5164\n",
      "\n",
      "Epoch 00075: saving model to data/checkpoint_vgg16/cp-0075.ckpt\n",
      "Epoch 76/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0051 - accuracy: 0.4445 - val_loss: 0.0031 - val_accuracy: 0.4507\n",
      "\n",
      "Epoch 00076: saving model to data/checkpoint_vgg16/cp-0076.ckpt\n",
      "Epoch 77/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0031 - accuracy: 0.4060 - val_loss: 0.0029 - val_accuracy: 0.5362\n",
      "\n",
      "Epoch 00077: saving model to data/checkpoint_vgg16/cp-0077.ckpt\n",
      "Epoch 78/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0030 - accuracy: 0.4461 - val_loss: 0.0029 - val_accuracy: 0.5329\n",
      "\n",
      "Epoch 00078: saving model to data/checkpoint_vgg16/cp-0078.ckpt\n",
      "Epoch 79/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0030 - accuracy: 0.4523 - val_loss: 0.0029 - val_accuracy: 0.5164\n",
      "\n",
      "Epoch 00079: saving model to data/checkpoint_vgg16/cp-0079.ckpt\n",
      "Epoch 80/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0030 - accuracy: 0.4549 - val_loss: 0.0029 - val_accuracy: 0.4868\n",
      "\n",
      "Epoch 00080: saving model to data/checkpoint_vgg16/cp-0080.ckpt\n",
      "Epoch 81/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0030 - accuracy: 0.4724 - val_loss: 0.0029 - val_accuracy: 0.5428\n",
      "\n",
      "Epoch 00081: saving model to data/checkpoint_vgg16/cp-0081.ckpt\n",
      "Epoch 82/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0030 - accuracy: 0.4651 - val_loss: 0.0029 - val_accuracy: 0.4836\n",
      "\n",
      "Epoch 00082: saving model to data/checkpoint_vgg16/cp-0082.ckpt\n",
      "Epoch 83/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0030 - accuracy: 0.4695 - val_loss: 0.0029 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 00083: saving model to data/checkpoint_vgg16/cp-0083.ckpt\n",
      "Epoch 84/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0030 - accuracy: 0.4542 - val_loss: 0.0029 - val_accuracy: 0.4836\n",
      "\n",
      "Epoch 00084: saving model to data/checkpoint_vgg16/cp-0084.ckpt\n",
      "Epoch 85/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0030 - accuracy: 0.4565 - val_loss: 0.0029 - val_accuracy: 0.4638\n",
      "\n",
      "Epoch 00085: saving model to data/checkpoint_vgg16/cp-0085.ckpt\n",
      "Epoch 86/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0030 - accuracy: 0.4656 - val_loss: 0.0029 - val_accuracy: 0.5592\n",
      "\n",
      "Epoch 00086: saving model to data/checkpoint_vgg16/cp-0086.ckpt\n",
      "Epoch 87/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0030 - accuracy: 0.4888 - val_loss: 0.0029 - val_accuracy: 0.5033\n",
      "\n",
      "Epoch 00087: saving model to data/checkpoint_vgg16/cp-0087.ckpt\n",
      "Epoch 88/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0030 - accuracy: 0.4669 - val_loss: 0.0029 - val_accuracy: 0.4770\n",
      "\n",
      "Epoch 00088: saving model to data/checkpoint_vgg16/cp-0088.ckpt\n",
      "Epoch 89/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0030 - accuracy: 0.4737 - val_loss: 0.0029 - val_accuracy: 0.5329\n",
      "\n",
      "Epoch 00089: saving model to data/checkpoint_vgg16/cp-0089.ckpt\n",
      "Epoch 90/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0030 - accuracy: 0.4688 - val_loss: 0.0029 - val_accuracy: 0.5296\n",
      "\n",
      "Epoch 00090: saving model to data/checkpoint_vgg16/cp-0090.ckpt\n",
      "Epoch 91/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0030 - accuracy: 0.4969 - val_loss: 0.0029 - val_accuracy: 0.4704\n",
      "\n",
      "Epoch 00091: saving model to data/checkpoint_vgg16/cp-0091.ckpt\n",
      "Epoch 92/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0030 - accuracy: 0.4740 - val_loss: 0.0028 - val_accuracy: 0.5132\n",
      "\n",
      "Epoch 00092: saving model to data/checkpoint_vgg16/cp-0092.ckpt\n",
      "Epoch 93/120\n",
      "240/240 [==============================] - 271s 1s/step - loss: 0.0030 - accuracy: 0.4792 - val_loss: 0.0029 - val_accuracy: 0.5197\n",
      "\n",
      "Epoch 00093: saving model to data/checkpoint_vgg16/cp-0093.ckpt\n",
      "Epoch 94/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0030 - accuracy: 0.4781 - val_loss: 0.0029 - val_accuracy: 0.5757\n",
      "\n",
      "Epoch 00094: saving model to data/checkpoint_vgg16/cp-0094.ckpt\n",
      "Epoch 95/120\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0029 - accuracy: 0.4862 - val_loss: 0.0029 - val_accuracy: 0.5164\n",
      "\n",
      "Epoch 00095: saving model to data/checkpoint_vgg16/cp-0095.ckpt\n",
      "Epoch 96/120\n",
      "240/240 [==============================] - 271s 1s/step - loss: 0.0030 - accuracy: 0.4753 - val_loss: 0.0029 - val_accuracy: 0.5296\n",
      "\n",
      "Epoch 00096: saving model to data/checkpoint_vgg16/cp-0096.ckpt\n",
      "Epoch 97/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0029 - accuracy: 0.4776 - val_loss: 0.0029 - val_accuracy: 0.5164\n",
      "\n",
      "Epoch 00097: saving model to data/checkpoint_vgg16/cp-0097.ckpt\n",
      "Epoch 98/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0030 - accuracy: 0.4773 - val_loss: 0.0029 - val_accuracy: 0.5395\n",
      "\n",
      "Epoch 00098: saving model to data/checkpoint_vgg16/cp-0098.ckpt\n",
      "Epoch 99/120\n",
      "240/240 [==============================] - 278s 1s/step - loss: 0.0029 - accuracy: 0.4958 - val_loss: 0.0029 - val_accuracy: 0.5493\n",
      "\n",
      "Epoch 00099: saving model to data/checkpoint_vgg16/cp-0099.ckpt\n",
      "Epoch 100/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0029 - accuracy: 0.4760 - val_loss: 0.0029 - val_accuracy: 0.5164\n",
      "\n",
      "Epoch 00100: saving model to data/checkpoint_vgg16/cp-0100.ckpt\n",
      "Epoch 101/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0029 - accuracy: 0.4786 - val_loss: 0.0028 - val_accuracy: 0.5658\n",
      "\n",
      "Epoch 00101: saving model to data/checkpoint_vgg16/cp-0101.ckpt\n",
      "Epoch 102/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0029 - accuracy: 0.4940 - val_loss: 0.0028 - val_accuracy: 0.5954\n",
      "\n",
      "Epoch 00102: saving model to data/checkpoint_vgg16/cp-0102.ckpt\n",
      "Epoch 103/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0029 - accuracy: 0.4766 - val_loss: 0.0028 - val_accuracy: 0.5362\n",
      "\n",
      "Epoch 00103: saving model to data/checkpoint_vgg16/cp-0103.ckpt\n",
      "Epoch 104/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0029 - accuracy: 0.4784 - val_loss: 0.0029 - val_accuracy: 0.5329\n",
      "\n",
      "Epoch 00104: saving model to data/checkpoint_vgg16/cp-0104.ckpt\n",
      "Epoch 105/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0029 - accuracy: 0.4875 - val_loss: 0.0028 - val_accuracy: 0.5954\n",
      "\n",
      "Epoch 00105: saving model to data/checkpoint_vgg16/cp-0105.ckpt\n",
      "Epoch 106/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0029 - accuracy: 0.4922 - val_loss: 0.0028 - val_accuracy: 0.5296\n",
      "\n",
      "Epoch 00106: saving model to data/checkpoint_vgg16/cp-0106.ckpt\n",
      "Epoch 107/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0029 - accuracy: 0.4935 - val_loss: 0.0028 - val_accuracy: 0.4967\n",
      "\n",
      "Epoch 00107: saving model to data/checkpoint_vgg16/cp-0107.ckpt\n",
      "Epoch 108/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0029 - accuracy: 0.4943 - val_loss: 0.0029 - val_accuracy: 0.4737\n",
      "\n",
      "Epoch 00108: saving model to data/checkpoint_vgg16/cp-0108.ckpt\n",
      "Epoch 109/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0029 - accuracy: 0.4932 - val_loss: 0.0028 - val_accuracy: 0.4770\n",
      "\n",
      "Epoch 00109: saving model to data/checkpoint_vgg16/cp-0109.ckpt\n",
      "Epoch 110/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0029 - accuracy: 0.4974 - val_loss: 0.0028 - val_accuracy: 0.5395\n",
      "\n",
      "Epoch 00110: saving model to data/checkpoint_vgg16/cp-0110.ckpt\n",
      "Epoch 111/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0029 - accuracy: 0.4820 - val_loss: 0.0029 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00111: saving model to data/checkpoint_vgg16/cp-0111.ckpt\n",
      "Epoch 112/120\n",
      "240/240 [==============================] - 278s 1s/step - loss: 0.0029 - accuracy: 0.4930 - val_loss: 0.0028 - val_accuracy: 0.5395\n",
      "\n",
      "Epoch 00112: saving model to data/checkpoint_vgg16/cp-0112.ckpt\n",
      "Epoch 113/120\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0029 - accuracy: 0.4966 - val_loss: 0.0028 - val_accuracy: 0.4605\n",
      "\n",
      "Epoch 00113: saving model to data/checkpoint_vgg16/cp-0113.ckpt\n",
      "Epoch 114/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0029 - accuracy: 0.4969 - val_loss: 0.0029 - val_accuracy: 0.5230\n",
      "\n",
      "Epoch 00114: saving model to data/checkpoint_vgg16/cp-0114.ckpt\n",
      "Epoch 115/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0029 - accuracy: 0.5052 - val_loss: 0.0028 - val_accuracy: 0.5164\n",
      "\n",
      "Epoch 00115: saving model to data/checkpoint_vgg16/cp-0115.ckpt\n",
      "Epoch 116/120\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0029 - accuracy: 0.4841 - val_loss: 0.0028 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00116: saving model to data/checkpoint_vgg16/cp-0116.ckpt\n",
      "Epoch 117/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0029 - accuracy: 0.4875 - val_loss: 0.0028 - val_accuracy: 0.5230\n",
      "\n",
      "Epoch 00117: saving model to data/checkpoint_vgg16/cp-0117.ckpt\n",
      "Epoch 118/120\n",
      "240/240 [==============================] - 276s 1s/step - loss: 0.0029 - accuracy: 0.5044 - val_loss: 0.0028 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00118: saving model to data/checkpoint_vgg16/cp-0118.ckpt\n",
      "Epoch 119/120\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0029 - accuracy: 0.5070 - val_loss: 0.0028 - val_accuracy: 0.5329\n",
      "\n",
      "Epoch 00119: saving model to data/checkpoint_vgg16/cp-0119.ckpt\n",
      "Epoch 120/120\n",
      "240/240 [==============================] - 273s 1s/step - loss: 0.0029 - accuracy: 0.4893 - val_loss: 0.0029 - val_accuracy: 0.5395\n",
      "\n",
      "Epoch 00120: saving model to data/checkpoint_vgg16/cp-0120.ckpt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "transfer_model.save('model_vgg')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: model_vgg/assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "transfer_model.save('data/vgg16.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "val_dataset = Dataset(IMG_RES, HMS_RES, NUM_LANDMARKS, VAL_DIR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset: ../Data/300W/eval.csv\n",
      "Train dataset is loaded. Shape: (600, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "def l2_distance(a, b):\n",
    "    d = a - b\n",
    "    error = 0.\n",
    "    for i, p in enumerate(d):\n",
    "        error += np.sqrt(p[0] ** 2 + p[1] ** 2)\n",
    "    error = error / d.shape[0]\n",
    "    return error"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "error = 0.\n",
    "for img, kps in tqdm(val_dataset.gen_vgg16(), desc='Evaluation'):\n",
    "    pred = transfer_model.predict(np.array([img]))\n",
    "    pred = np.reshape(pred, pred.shape[-1]) * 256\n",
    "    pred_kps = np.zeros((int(pred.shape[0] / 2), 2))\n",
    "    for i in range(pred_kps.shape[0]):\n",
    "        pred_kps[i] = pred[i*2:i*2+2]\n",
    "    # plt.imshow(img)\n",
    "    # plt.scatter(pred_kps[:,0], pred_kps[:,1])\n",
    "    orig_kps = np.zeros((int(pred.shape[0] / 2), 2))\n",
    "    for i in range(orig_kps.shape[0]):\n",
    "        orig_kps[i] = kps[i*2:i*2+2] * 256\n",
    "    # plt.scatter(orig_kps[:,0], orig_kps[:,1])\n",
    "    error += l2_distance(orig_kps, pred_kps)\n",
    "error = error / 600\n",
    "print(error)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluation: 600it [01:30,  6.67it/s]\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}