{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\t\t\n",
    "\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "vgg_model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "x = vgg_model.output\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x) # Dropout layer to reduce overfitting\n",
    "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(136, activation='relu')(x) # Softmax for multiclass\n",
    "transfer_model = tf.keras.Model(inputs=vgg_model.input, outputs=x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=8, verbose=1, mode='max', min_lr=5e-5)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('vgg16_finetune.h15', monitor= 'val_accuracy', mode='max', save_best_only=True, verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "learning_rate= 5e-5\n",
    "transfer_model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=[\"accuracy\"])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\n",
    "from libs.dp import Dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# checkpoint\n",
    "\n",
    "checkpoint_path = \"data/checkpoint_vgg16/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1, \n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch')\n",
    "\n",
    "transfer_model.save_weights(checkpoint_path.format(epoch=0))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "IMG_RES = 256\n",
    "HMS_RES = 64\n",
    "NUM_LANDMARKS = 68\n",
    "BATCH_SIZE = 16\n",
    "DATASET_DIR = '../Data/300W_train/train.csv'\n",
    "\n",
    "dataset = Dataset(IMG_RES, HMS_RES, NUM_LANDMARKS, DATASET_DIR)\n",
    "# dataset_generator = "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset: ../Data/300W_train/train.csv\n",
      "Train dataset is loaded. Shape: (3837, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tf_dataset = tf.data.Dataset.from_generator(dataset.gen_vgg16,\n",
    "                                            output_types=(np.float32, np.float32),\n",
    "                                            output_shapes=(\n",
    "                                                [IMG_RES, IMG_RES, 3],\n",
    "                                                [NUM_LANDMARKS * 2]),\n",
    "                                            args=()).repeat().batch(BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "VAL_DIR = '../Data/300W/eval.csv'\n",
    "val_dataset = Dataset(IMG_RES, HMS_RES, NUM_LANDMARKS, VAL_DIR)\n",
    "val_tf_dataset = tf.data.Dataset.from_generator(dataset.gen_vgg16,\n",
    "                                                output_types=(np.float32, np.float32),\n",
    "                                                output_shapes=(\n",
    "                                                    [IMG_RES, IMG_RES, 3],\n",
    "                                                    [NUM_LANDMARKS * 2]),\n",
    "                                                args=()).repeat().batch(BATCH_SIZE)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train dataset: ../Data/300W/eval.csv\n",
      "Train dataset is loaded. Shape: (600, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "hist = transfer_model.fit(tf_dataset.take(240), validation_data=val_tf_dataset.take(19), callbacks=[lr_reduce], epochs=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "240/240 [==============================] - 284s 1s/step - loss: 0.0659 - accuracy: 0.0789 - val_loss: 0.0186 - val_accuracy: 0.2928\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 279s 1s/step - loss: 0.0244 - accuracy: 0.1042 - val_loss: 0.0101 - val_accuracy: 0.2237\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 279s 1s/step - loss: 0.0168 - accuracy: 0.1237 - val_loss: 0.0109 - val_accuracy: 0.1513\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0148 - accuracy: 0.1385 - val_loss: 0.0101 - val_accuracy: 0.1283\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 281s 1s/step - loss: 0.0135 - accuracy: 0.1474 - val_loss: 0.0092 - val_accuracy: 0.2007\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 278s 1s/step - loss: 0.0128 - accuracy: 0.1487 - val_loss: 0.0088 - val_accuracy: 0.2599\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 277s 1s/step - loss: 0.0122 - accuracy: 0.1651 - val_loss: 0.0085 - val_accuracy: 0.1941\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 275s 1s/step - loss: 0.0119 - accuracy: 0.1609 - val_loss: 0.0083 - val_accuracy: 0.2961\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 272s 1s/step - loss: 0.0114 - accuracy: 0.1570 - val_loss: 0.0085 - val_accuracy: 0.1941\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0109 - accuracy: 0.1620 - val_loss: 0.0095 - val_accuracy: 0.2862\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0106 - accuracy: 0.1711 - val_loss: 0.0083 - val_accuracy: 0.2566\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 283s 1s/step - loss: 0.0103 - accuracy: 0.1690 - val_loss: 0.0086 - val_accuracy: 0.1776\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 274s 1s/step - loss: 0.0101 - accuracy: 0.1836 - val_loss: 0.0079 - val_accuracy: 0.3158\n",
      "Epoch 14/100\n",
      "186/240 [======================>.......] - ETA: 57s - loss: 0.0099 - accuracy: 0.1811"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}